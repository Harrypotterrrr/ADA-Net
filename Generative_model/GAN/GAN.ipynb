{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "img_path = \"./img_save/CNN_adam/\"\n",
    "plot_path = \"./plot_save/\"\n",
    "\n",
    "class GAN():\n",
    "    \n",
    "    dis_type = 0\n",
    "    debug = True\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        self.img_row = 28\n",
    "        self.img_col = 28\n",
    "        self.img_channel = 1\n",
    "        self.img_shape = (self.img_row, self.img_col, self.img_channel)\n",
    "        self.latent_dim = 100\n",
    "        \n",
    "        # input noisy layer\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        \n",
    "        # generator network\n",
    "        self.genNet = self.generator_build()\n",
    "        \n",
    "        # generate image from generator network\n",
    "        imgGenerate = self.genNet(z)\n",
    "        \n",
    "        # discriminator network\n",
    "        if self.dis_type == 0:\n",
    "            self.disNet = self.discriminator_build_fc()\n",
    "        elif self.dis_type == 1:\n",
    "            self.disNet = self.discriminator_build_cnn()\n",
    "        \n",
    "        # only train the generator network for whole model training stage\n",
    "        self.disNet.trainable = False\n",
    "        \n",
    "        if self.debug == True:\n",
    "            print(imgGenerate.shape)\n",
    "        \n",
    "        # output layer\n",
    "        label = self.disNet(imgGenerate)\n",
    "\n",
    "        # the GAN model network\n",
    "        self.modelNet = Model(z, label)\n",
    "        \n",
    "         # set ganNet compiling\n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        self.modelNet.compile(loss='binary_crossentropy',\n",
    "                            optimizer=optimizer,\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    def generator_build(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "                  \n",
    "    def discriminator_build_cnn(self, optimizer_type='adam'):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, (3, 3), strides=(1, 1)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        model.add(Conv2D(64, (3, 3), strides=(1, 1)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(1, activation='relu'))\n",
    "        \n",
    "        # input & output layer\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = model(img)\n",
    "      \n",
    "        disNet = Model(img, label)\n",
    "        \n",
    "#         optimizer = Adam(lr=0.00005, beta_1=0.9)\n",
    "        optimizer = SGD(lr=0.0001, decay=1e-7, momentum=0.9, nesterov=True)\n",
    "        disNet.compile(loss='binary_crossentropy', \n",
    "                      optimizer=optimizer,\n",
    "                     metrics=['accuracy'])\n",
    "          \n",
    "        model.summary()\n",
    "        \n",
    "        return disNet\n",
    "\n",
    "    def discriminator_build_fc(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = model(img)\n",
    "        \n",
    "        disNet = Model(img, label)\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        disNet.compile(loss='binary_crossentropy', \n",
    "                      optimizer=optimizer,\n",
    "                     metrics=['accuracy'])\n",
    "        \n",
    "        disNet.summary()\n",
    "        \n",
    "        return disNet\n",
    "    \n",
    "    \n",
    "    def save_sampling(self, epoch):\n",
    "        \n",
    "        row, col = 5, 5\n",
    "        noise = np.random.random((row * col, self.latent_dim))\n",
    "        img_gens = self.genNet.predict(noise)\n",
    "        img_gens = img_gens.reshape((len(img_gens), self.img_row, self.img_col))\n",
    "        \n",
    "        fig, axs = plt.subplots(row, col)\n",
    "        \n",
    "        ctr = 0\n",
    "        for r in range(row):\n",
    "            for c in range(col):\n",
    "                axs[r, c].imshow(img_gens[ctr], cmap='gray')\n",
    "                axs[r, c].axis('off')\n",
    "                ctr += 1\n",
    "                \n",
    "        if not os.path.isdir(img_path):\n",
    "            os.mkdir(img_path)\n",
    "            print(\"make new\", img_path, \"path!\")\n",
    "    \n",
    "        fig.savefig(img_path+\"%d.png\" % epoch)\n",
    "        plt.close()\n",
    "            \n",
    "    def graph_summary(self, loss_dis, acc_dis, loss_gen, acc_gen):\n",
    "    \n",
    "        a, b = 2, 1\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "        axs[0].plot(loss_dis, color='red', label='loss_dis')\n",
    "        axs[0].plot(loss_gen, color='orange', label='loss_gen')\n",
    "        axs[0].set(xlabel='Epoch', ylabel='Loss', title=\"Loss of Discriminator & Generator\")\n",
    "        axs[0].legend()\n",
    "\n",
    "        axs[1].plot(acc_dis, color='blue', label='acc_dis')\n",
    "        axs[1].plot(acc_gen, color='green', label='acc_gen')\n",
    "        axs[1].set(xlabel='Epoch', ylabel='Acc', title=\"Accuracy of Discriminator & Generator\")\n",
    "        axs[1].legend()\n",
    "\n",
    "        if not os.path.isdir(plot_path):\n",
    "            os.mkdir(plot_path)\n",
    "            print(\"make new\", plot_path, \"path!\")\n",
    "        fig.savefig(plot_path+\"fig.png\")\n",
    "\n",
    "\n",
    "    def build_poolSample(self, batch_size):\n",
    "\n",
    "        # load dataset\n",
    "        (real_pool, _), (_, _) = mnist.load_data()\n",
    "        \n",
    "        # rescale 0 to 1 & increase dimision\n",
    "        real_pool = real_pool / 255.\n",
    "        \n",
    "        # expand dimension to (num, row, col, 1)\n",
    "        real_pool = np.expand_dims(real_pool, axis=3)\n",
    "        \n",
    "        # build adversarial label\n",
    "        label_positive = np.ones((batch_size, 1))\n",
    "        label_negative = np.zeros((batch_size, 1))\n",
    "        label_pool = np.concatenate((label_positive, label_negative))\n",
    "\n",
    "        # build index to be shuffled for each epoch\n",
    "        maxn = max(len(real_pool), batch_size)\n",
    "        index = [x for x in range(len(real_pool))]\n",
    "        \n",
    "        if self.debug == True:\n",
    "            print(\"index.len:\", len(index))\n",
    "            \n",
    "        return real_pool, label_pool, index\n",
    "        \n",
    "    \n",
    "    def build_trainSample(self, real_pool, label_pool, index, batch_size=128, shuffle=True):\n",
    "        \n",
    "        # build noise\n",
    "        noise = np.random.random((batch_size, self.latent_dim))\n",
    "\n",
    "        # build fake img\n",
    "        fake_img = self.genNet.predict(noise)\n",
    "\n",
    "        # build random index of real_pool\n",
    "        index_epoch = np.random.choice(index, size=batch_size, replace=False)\n",
    "\n",
    "        if self.debug is True:\n",
    "            print(\"index_epoch.shape:\", index_epoch.shape)\n",
    "\n",
    "        # build pos & neg train sample\n",
    "        # X_train_positive = real_pool[index_epoch]\n",
    "        X_train_positive = real_pool[[0]*batch_size]\n",
    "        X_train_negative = fake_img\n",
    "\n",
    "        X_train_epoch = np.concatenate((X_train_positive, X_train_negative))\n",
    "\n",
    "        if self.debug is True:\n",
    "            print(\"X_train_positive.shape:\", X_train_positive.shape)\n",
    "            print(\"X_train_negative.shape:\", X_train_negative.shape)\n",
    "            print(\"X_train_epoch.shape:\", X_train_epoch.shape)\n",
    "\n",
    "        # shuffle the train samples\n",
    "\n",
    "        if shuffle is True:\n",
    "            zipped = list(zip(X_train_epoch, label_pool))\n",
    "            np.random.shuffle(zipped)\n",
    "            X_train, Y_train = map(np.asarray, zip(*zipped))\n",
    "        else:\n",
    "            X_train, Y_train = X_train_epoch, label_pool\n",
    "\n",
    "        if self.debug is True:\n",
    "            print(\"X_train.shape:\", X_train.shape)\n",
    "            print(\"Y_train.shape:\", Y_train.shape)\n",
    "            self.debug = False   \n",
    "            \n",
    "        return noise, X_train, Y_train\n",
    "        \n",
    " \n",
    "    def train_model(self, epochs, batch_size=128, trainGen_interval=5, sample_interval=20, save_interval=200, shuffle=True):\n",
    "        \n",
    "        batch_size = batch_size // 2\n",
    "        \n",
    "        # build sample pool\n",
    "        real_pool, label_pool, index = self.build_poolSample(batch_size)\n",
    "        \n",
    "        loss_dis = []\n",
    "        acc_dis = []\n",
    "        loss_mod = []\n",
    "        acc_mod = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # build training sample\n",
    "            noise, X_train, Y_train = self.build_trainSample(real_pool, label_pool, index, batch_size, shuffle)\n",
    "            \n",
    "            # train the discriminator net\n",
    "            l_dis, a_dis = self.disNet.train_on_batch(X_train, Y_train)\n",
    "\n",
    "            # train the whole net with discriminator network untrainable\n",
    "            l_mod, a_mod = self.modelNet.train_on_batch(noise, Y_train[:batch_size])\n",
    "            \n",
    "            # print current property\n",
    "            print (\"%d [D loss: %f, acc: %.2f%%] [G loss: %f, acc: %.2f%%]\" % (epoch, l_dis, a_dis * 100., l_mod, a_mod * 100))\n",
    "            \n",
    "            if epoch % sample_interval == 0:\n",
    "                loss_dis.append(l_dis)\n",
    "                acc_dis.append(a_dis)\n",
    "                loss_mod.append(l_mod)\n",
    "                acc_mod.append(a_mod)\n",
    "                \n",
    "            # save image of training procedure\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_sampling(epoch)\n",
    "        \n",
    "        # show losses and accuracies figure\n",
    "        self.graph_summary(loss_dis, acc_dis, loss_mod, acc_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gan = GAN()\n",
    "    gan.train_model(2000, batch_size=64, sample_interval=20, save_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
