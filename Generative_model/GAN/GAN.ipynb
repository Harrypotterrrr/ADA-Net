{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "save_path = \"./img_save/\"\n",
    "class GAN():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.img_row = 28\n",
    "        self.img_col = 28\n",
    "        self.img_channel = 1\n",
    "        self.img_shape = (self.img_row, self.img_col, self.img_channel)\n",
    "        self.latent_dim = 100\n",
    "        \n",
    "        # input noisy layer\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        \n",
    "        # generator network\n",
    "        self.genNet = self.generator_build()\n",
    "        \n",
    "        # generate image from generator network\n",
    "        imgGenerate = self.genNet(z)\n",
    "        \n",
    "        # discriminator network\n",
    "        self.disNet = self.discriminator_build()\n",
    "        \n",
    "        # only train the generator network for whole model training stage\n",
    "        self.disNet.trainable = False\n",
    "        \n",
    "#         optimizer = Adam(lr=0.001, beta_1=0.9)\n",
    "#         self.disNet.compile(loss='binary_crossentropy', \n",
    "#                       optimizer=optimizer,\n",
    "#                      metrics=['accuracy'])\n",
    "        \n",
    "        print(imgGenerate.shape)\n",
    "        \n",
    "        # output layer\n",
    "        label = self.disNet(imgGenerate)\n",
    "\n",
    "        # the GAN model network\n",
    "        self.modelNet = Model(z, label)\n",
    "        \n",
    "         # set ganNet compiling\n",
    "        optimizer = Adam(lr=0.001, beta_1=0.9)\n",
    "        self.modelNet.compile(loss='binary_crossentropy',\n",
    "                            optimizer=optimizer,\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "    def generator_build(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        \n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        \n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        \n",
    "        model.add(Dense(np.prod(self.img_shape), activation='relu'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "        \n",
    "#         model.add(Conv2())  ?\n",
    "        \n",
    "        # input & output layer\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        imgGenerate = model(noise)\n",
    "        \n",
    "#         model.summary()\n",
    "\n",
    "        return Model(noise, imgGenerate)\n",
    "\n",
    "                  \n",
    "    def discriminator_build(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(64, (3, 3), strides=(1, 1)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "        \n",
    "        model.add(Conv2D(128, (3, 3), strides=(1, 1)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(1, activation='relu'))\n",
    "        \n",
    "        # input & output layer\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = model(img)\n",
    "      \n",
    "        disNet = Model(img, label)\n",
    "        \n",
    "        optimizer = Adam(lr=0.001, beta_1=0.9)\n",
    "        disNet.compile(loss='binary_crossentropy', \n",
    "                      optimizer=optimizer,\n",
    "                     metrics=['accuracy'])\n",
    "          \n",
    "#         model.summary()\n",
    "        \n",
    "        return disNet\n",
    "        \n",
    "    def save_sampling(self, epoch):\n",
    "        \n",
    "        row, col = 5, 5\n",
    "        noise = np.random.random((row * col, self.latent_dim))\n",
    "        img_gens = self.genNet.predict(noise)\n",
    "        img_gens = img_gens.reshape((len(img_gens), self.img_row, self.img_col))\n",
    "        \n",
    "        fig, axs = plt.subplots(row, col)\n",
    "        \n",
    "        ctr = 0\n",
    "        for r in range(row):\n",
    "            for c in range(col):\n",
    "#                 print(img_gens[ctr].shape)\n",
    "#                 plt.imshow(img_gens[ctr], cmap='gray')\n",
    "#                 input()\n",
    "                axs[r, c].imshow(img_gens[ctr], cmap='gray')\n",
    "                axs[r, c].axis('off')\n",
    "                ctr += 1\n",
    "                \n",
    "        if not os.path.isdir(save_path):\n",
    "            os.mkdir(save_path)\n",
    "            print(\"make new\", save_path, \"path!\")   \n",
    "    \n",
    "        fig.savefig(save_path+\"%d.png\" % epoch)\n",
    "        plt.close()\n",
    "            \n",
    "    def graph_summary(self, loss_dis, acc_dis, loss_gen, acc_gen):\n",
    "    \n",
    "        len_dis = len(loss_dis)\n",
    "        len_gen = len(loss_gen)\n",
    "        a, b = 2, 2\n",
    "        fig, axs = plt.subplots(a, b)\n",
    "        axs[0, 0] = plt.scatter(np.arange(len_dis), loss_dis)\n",
    "#         axs[0, 0].plot(loss_dis)\n",
    "        axs[0, 1] = plt.scatter(np.arange(len_dis), acc_dis)\n",
    "        axs[1, 0] = plt.scatter(np.arange(len_gen), loss_gen)\n",
    "        axs[0, 1] = plt.scatter(np.arange(len_gen), acc_gen)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    \n",
    "    def train_model(self, epochs, batch_size=128, trainGen_interval=5, sample_interval=50):\n",
    "        \n",
    "        batch_size = batch_size // 2\n",
    "        \n",
    "        # load dataset\n",
    "        (real_pool, _), (_, _) = mnist.load_data()\n",
    "        \n",
    "        # rescale 0 to 1 & increase dimision\n",
    "        real_pool = real_pool / 255.\n",
    "        real_pool = np.expand_dims(real_pool, axis=3)\n",
    "        \n",
    "        # build adversarial label\n",
    "        label_positive = np.ones((batch_size, 1))\n",
    "        label_negative = np.zeros((batch_size, 1))\n",
    "        Y_train = np.concatenate((label_positive, label_negative))\n",
    "        \n",
    "        # build index to be shuffled for each epoch\n",
    "        maxnn = max(len(real_pool), batch_size)\n",
    "        index = [x for x in range(maxnn)]\n",
    "        \n",
    "        loss_dis = []\n",
    "        acc_dis = []\n",
    "        loss_gen = []\n",
    "        acc_gen = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # build noise\n",
    "            noise = np.random.random((batch_size, self.latent_dim))\n",
    "            \n",
    "            # build fake img\n",
    "            fake_img = self.genNet.predict(noise)\n",
    "            \n",
    "            # build train sample for this epoch\n",
    "            index_epoch = index[:batch_size]\n",
    "            np.random.shuffle(index_epoch)\n",
    "            X_train_positive = real_pool[index_epoch]\n",
    "            X_train_negative = fake_img\n",
    "            \n",
    "            X_train_epoch = np.concatenate((X_train_positive,X_train_negative))\n",
    "            \n",
    "            zipped = list(zip(X_train_epoch, Y_train))\n",
    "            np.random.shuffle(zipped)\n",
    "            X_train, Y_train = map(np.asarray, zip(*zipped))\n",
    "            \n",
    "            # train the discriminator net\n",
    "            l, a = self.disNet.train_on_batch(X_train, Y_train)\n",
    "            loss_dis.append(l)\n",
    "            acc_dis.append(a)\n",
    "            \n",
    "            # train the whole net with discriminator network untrainable\n",
    "            l, a = self.modelNet.train_on_batch(noise, Y_train[:batch_size])\n",
    "            loss_gen.append(l)\n",
    "            acc_gen.append(a)\n",
    "            \n",
    "            if epoch == sample_interval:\n",
    "                self.save_sampling(epoch)\n",
    "        \n",
    "        self.graph_summary(loss_dis, acc_dis, loss_gen, acc_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    gan = GAN()\n",
    "    gan.train_model(2000, batch_size=32, sample_interval = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
